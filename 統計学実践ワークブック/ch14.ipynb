{"cells":[{"cell_type":"markdown","metadata":{},"source":["## 良さそうなサイト\n","https://manabitimes.jp/math/1060\n"]},{"cell_type":"markdown","metadata":{},"source":["## マルコフ連鎖とは\n","\n","マルコフ連鎖（Markov Chain）は、次の状態が現在の状態のみに依存し、過去の状態には依存しない特性を持つ確率過程です。これを「マルコフ性」と呼びます。具体的には、現在の状態が与えられたとき、次の状態の確率分布が過去のどの状態にも依存せず、現在の状態だけによって決定されます。\n","\n","### 形式的な定義\n","\n","マルコフ連鎖は、離散時間における確率過程 $\\{X_t\\}_{t \\geq 0}$ で、任意の時間点 $t$ と任意の状態 $x_0, x_1, \\ldots, x_t$ について、次の条件が成り立ちます：\n","\n","$$\n","P(X_{t+1} = x_{t+1} \\mid X_t = x_t, X_{t-1} = x_{t-1}, \\ldots, X_0 = x_0) = P(X_{t+1} = x_{t+1} \\mid X_t = x_t)\n","$$\n","\n","### 状態遷移行列\n","\n","マルコフ連鎖は、状態遷移行列（Transition Matrix）によって特徴付けられます。この行列 $P$ の各要素 $P_{ij}$ は、状態 $i$ から状態 $j$ への遷移確率を表します：\n","\n","$$\n","P_{ij} = P(X_{t+1} = j \\mid X_t = i)\n","$$\n","\n","### 例\n","\n","簡単な例として、3つの状態（A, B, C）を持つマルコフ連鎖を考えます。この場合の状態遷移行列は次のようになります：\n","\n","$$\n","P = \\begin{pmatrix}\n","0.1 & 0.6 & 0.3 \\\\\n","0.4 & 0.3 & 0.3 \\\\\n","0.2 & 0.5 & 0.3\n","\\end{pmatrix}\n","$$\n","\n","この行列は、例えば、状態Aから状態Bへの遷移確率が0.6、状態Bから状態Cへの遷移確率が0.3であることを示しています。\n","\n","### Pythonでの実装例\n","\n","以下は、Pythonを使ってマルコフ連鎖をシミュレートする簡単なコード例です。\n","\n","\n","\n","このコードでは、初期状態を状態Aとし、10回の遷移をシミュレートしています。"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["States: [0, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1]\n"]}],"source":["import numpy as np\n","\n","# 状態遷移行列\n","P = np.array([\n","    [0.1, 0.6, 0.3],\n","    [0.4, 0.3, 0.3],\n","    [0.2, 0.5, 0.3]\n","])\n","\n","# 初期状態\n","current_state = 0  # 状態A\n","\n","# 状態の記録\n","states = [current_state]\n","\n","# 遷移のシミュレーション\n","np.random.seed(0)\n","for _ in range(10):\n","    current_state = np.random.choice([0, 1, 2], p=P[current_state])\n","    states.append(current_state)\n","\n","print(\"States:\", states)"]},{"cell_type":"markdown","metadata":{},"source":["## 定常マルコフ連鎖とは\n","\n","定常マルコフ連鎖（Stationary Markov Chain）は、長時間の後に状態の分布が時間によらず一定になる特性を持つマルコフ連鎖です。これを「定常分布」または「定常状態」と呼びます。定常分布が存在する場合、マルコフ連鎖がどの初期状態から始まっても、時間が経つにつれて状態の分布はこの定常分布に収束します。\n","\n","### 定常分布の定義\n","\n","定常分布 $\\pi$ は次の条件を満たします：\n","\n","$$\n","\\pi P = \\pi\n","$$\n","\n","ここで、$\\pi$ は状態の確率ベクトル（全ての状態の確率を持つベクトル）で、$P$ は状態遷移行列です。この方程式は、状態分布が一歩進んでも変わらないことを意味します。\n","\n","### 定常分布の特徴\n","\n","1. **一意性**: 連鎖が不可約かつ周期的でない場合、定常分布は一意に存在します。\n","2. **収束性**: 初期状態に依存せず、長時間後には定常分布に収束します。\n","\n","### 例\n","\n","上記の状態遷移行列を再利用して定常分布を求めてみましょう：\n","\n","$$\n","P = \\begin{pmatrix}\n","0.1 & 0.6 & 0.3 \\\\\n","0.4 & 0.3 & 0.3 \\\\\n","0.2 & 0.5 & 0.3\n","\\end{pmatrix}\n","$$\n","\n","### Pythonでの実装例\n","\n","以下は、Pythonを使って定常分布を求める例です。\n","\n","\n","\n","このコードでは、行列方程式を解くことで定常分布を求めています。定常分布は、連鎖が長時間の後に収束する状態の確率を表します。"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["定常分布: [0.26153846 0.43846154 0.3       ]\n"]}],"source":["\n","import numpy as np\n","\n","# 状態遷移行列\n","P = np.array([\n","    [0.1, 0.6, 0.3],\n","    [0.4, 0.3, 0.3],\n","    [0.2, 0.5, 0.3]\n","])\n","\n","# 行列のサイズ\n","n = P.shape[0]\n","\n","# 定常分布を求めるための連立方程式\n","A = np.vstack((P.T - np.eye(n), np.ones(n)))\n","b = np.append(np.zeros(n), 1)\n","\n","# 解を求める\n","pi = np.linalg.lstsq(A, b, rcond=None)[0]\n","\n","print(\"定常分布:\", pi)\n"]},{"cell_type":"markdown","metadata":{},"source":["## 定常マルコフ連鎖の収束\n","\n","はい、定常マルコフ連鎖では、時間が経つにつれて状態の分布が一定の確率分布に収束します。この確率分布を定常分布（Stationary Distribution）と言います。定常分布は、マルコフ連鎖が長い時間にわたって観測されるときに、各状態がどれくらいの頻度で出現するかを示します。\n","\n","### 収束の具体例\n","\n","例えば、先ほどの状態遷移行列を再利用して考えます：\n","\n","$$\n","P = \\begin{pmatrix}\n","0.1 & 0.6 & 0.3 \\\\\n","0.4 & 0.3 & 0.3 \\\\\n","0.2 & 0.5 & 0.3\n","\\end{pmatrix}\n","$$\n","\n","この行列を用いると、どの初期状態から始めても、時間が経つにつれて各状態に対する確率は一定の分布に収束します。\n","\n","### 収束の確認\n","\n","\n","\n","このコードは、初期状態を状態A（ベクトルで表すと [1, 0, 0] ）として設定し、1000回の状態遷移を繰り返します。最後に得られる `state_distribution` が定常分布に近づきます。\n","\n","### 定常分布の計算\n","\n","さらに、前のセクションで説明した方法で定常分布を計算することもできます。\n","\n","```python\n","import numpy as np\n","\n","# 状態遷移行列\n","P = np.array([\n","    [0.1, 0.6, 0.3],\n","    [0.4, 0.3, 0.3],\n","    [0.2, 0.5, 0.3]\n","])\n","\n","# 行列のサイズ\n","n = P.shape[0]\n","\n","# 定常分布を求めるための連立方程式\n","A = np.vstack((P.T - np.eye(n), np.ones(n)))\n","b = np.append(np.zeros(n), 1)\n","\n","# 解を求める\n","pi = np.linalg.lstsq(A, b, rcond=None)[0]\n","\n","print(\"計算された定常分布:\", pi)\n","```\n","\n","このコードでは、定常分布を行列方程式を解くことで求めます。シミュレーション結果と一致するはずです。\n","\n","### まとめ\n","\n","定常マルコフ連鎖は、時間が経つにつれて各状態の出現確率が一定の分布に収束する特性を持ちます。この定常分布は、マルコフ連鎖がどの状態から始まっても、長い時間の後に同じ分布に収束することを示しています。"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["収束した状態分布: [0.26153846 0.43846154 0.3       ]\n"]}],"source":["import numpy as np\n","\n","# 状態遷移行列\n","P = np.array([\n","    [0.1, 0.6, 0.3],\n","    [0.4, 0.3, 0.3],\n","    [0.2, 0.5, 0.3]\n","])\n","\n","# 初期状態ベクトル\n","state_distribution = np.array([1, 0, 0])  # 初期状態Aに全ての確率を持つ\n","\n","# 繰り返し回数\n","iterations = 1000\n","\n","# 状態遷移を繰り返す\n","for _ in range(iterations):\n","    state_distribution = state_distribution @ P\n","\n","print(\"収束した状態分布:\", state_distribution)\n"]}],"metadata":{"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":4}
