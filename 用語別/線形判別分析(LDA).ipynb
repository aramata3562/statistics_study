{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 正準判別分析について\n",
    "\n",
    "正準判別分析（Canonical Discriminant Analysis, CDA）または線形判別分析（Linear Discriminant Analysis, LDA）は、多変量統計手法の一つで、複数のクラスにわたるデータセットを分類するために使用されます。LDAは、データセットを低次元の空間に変換し、異なるクラスを可能な限り分離することを目的としています。\n",
    "\n",
    "### 基本的な考え方\n",
    "\n",
    "正準判別分析の目標は、異なるクラス間の分離を最大化し、同じクラス内の分散を最小化することです。これにより、データを最適に分類する線形判別関数を見つけることができます。\n",
    "\n",
    "### 手順\n",
    "\n",
    "1. **クラスごとの平均ベクトルの計算**：\n",
    "   各クラスの平均ベクトル $\\mu_i$ を計算します。\n",
    "\n",
    "2. **クラス内散布行列（Within-class scatter matrix）$S_W$ の計算**：\n",
    "   各クラス内の散布行列を計算し、それらを合計してクラス内散布行列 $S_W$ を求めます。\n",
    "\n",
    "3. **クラス間散布行列（Between-class scatter matrix）$S_B$ の計算**：\n",
    "   クラス間の散布行列を計算します。\n",
    "\n",
    "4. **判別関数の計算**：\n",
    "   クラス内散布行列とクラス間散布行列を用いて一般固有値問題を解き、最大の固有値に対応する固有ベクトルを求めます。この固有ベクトルが判別関数の係数となります。\n",
    "\n",
    "### 実装例\n",
    "\n",
    "以下に、Pythonを用いて正準判別分析を実装する例を示します。ここでは、Irisデータセットを使用します。\n",
    "\n",
    "\n",
    "このコードでは、LDAを使用してIrisデータセットを2次元に変換し、各クラスのデータ点をプロットしています。各クラスは異なる色で表示され、LDAによってうまく分離されていることがわかります。\n",
    "\n",
    "### 計算過程の詳細\n",
    "\n",
    "#### 1. クラスごとの平均ベクトルの計算\n",
    "各クラスの平均ベクトルを計算します。例えば、クラス $i$ の平均ベクトル $\\mu_i$ は以下のように計算されます：\n",
    "$$\n",
    "\\mu_i = \\frac{1}{N_i} \\sum_{x_k \\in \\mathcal{X}_i} x_k\n",
    "$$\n",
    "ここで、$N_i$ はクラス $i$ に属するデータ点の数、$\\mathcal{X}_i$ はクラス $i$ のデータ点の集合です。\n",
    "\n",
    "#### 2. クラス内散布行列の計算\n",
    "クラス内散布行列 $S_W$ は、各クラスの散布行列 $S_i$ の合計です：\n",
    "$$\n",
    "S_W = \\sum_{i=1}^c S_i = \\sum_{i=1}^c \\sum_{x_k \\in \\mathcal{X}_i} (x_k - \\mu_i)(x_k - \\mu_i)^T\n",
    "$$\n",
    "\n",
    "#### 3. クラス間散布行列の計算\n",
    "クラス間散布行列 $S_B$ は以下のように計算されます：\n",
    "$$\n",
    "S_B = \\sum_{i=1}^c N_i (\\mu_i - \\mu)(\\mu_i - \\mu)^T\n",
    "$$\n",
    "ここで、$\\mu$ は全データの平均ベクトルです。\n",
    "\n",
    "#### 4. 判別関数の計算\n",
    "クラス内散布行列 $S_W$ とクラス間散布行列 $S_B$ を用いて、次の一般固有値問題を解きます：\n",
    "$$\n",
    "S_W^{-1} S_B w = \\lambda w\n",
    "$$\n",
    "最大の固有値 $\\lambda$ に対応する固有ベクトル $w$ が判別関数の係数となります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "# データセットの読み込み\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# LDAの適用\n",
    "lda = LDA(n_components=2)\n",
    "X_r = lda.fit(X, y).transform(X)\n",
    "\n",
    "# プロット\n",
    "plt.figure()\n",
    "colors = ['red', 'green', 'blue']\n",
    "target_names = iris.target_names\n",
    "for color, i, target_name in zip(colors, [0, 1, 2], target_names):\n",
    "    plt.scatter(X_r[y == i, 0], X_r[y == i, 1], alpha=.8, color=color,\n",
    "                label=target_name)\n",
    "plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "plt.title('LDA of IRIS dataset')\n",
    "\n",
    "plt.xlabel('LD1')\n",
    "plt.ylabel('LD2')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
