{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## トービットモデルについて\n",
    "\n",
    "トービットモデル（Tobit Model）は、経済学や他の社会科学で一般的に使用される回帰モデルで、特に左または右で検閲されたデータを扱うために設計されています。例えば、ある値以下または以上の値が検出不能な場合や、報告されない場合に適用されます。\n",
    "\n",
    "### トービットモデルの基本概念\n",
    "\n",
    "トービットモデルは、連続応答変数 $Y_i^*$ が観測できないか、一定の閾値（トランケーションポイント）により検閲される場合に使用されます。観測される応答変数 $Y_i$ は次のように定義されます：\n",
    "\n",
    "$$\n",
    "Y_i =\n",
    "\\begin{cases} \n",
    "Y_i^* & \\text{if } Y_i^* > L \\\\\n",
    "L & \\text{if } Y_i^* \\leq L\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "ここで、\n",
    "- $Y_i^*$ は潜在変数（観測されない真の値）\n",
    "- $L$ は検閲の閾値（例えば、$L = 0$ の場合、非負のデータが観測される）\n",
    "\n",
    "潜在変数 $Y_i^*$ は次のように定義されます：\n",
    "\n",
    "$$\n",
    "Y_i^* = X_i \\beta + \\epsilon_i\n",
    "$$\n",
    "\n",
    "ここで、\n",
    "- $X_i$ は説明変数のベクトル\n",
    "- $\\beta$ はパラメータのベクトル\n",
    "- $\\epsilon_i$ は通常の誤差項で、標準正規分布に従う\n",
    "\n",
    "### トービットモデルの利点と制限\n",
    "- **利点**:\n",
    "  - データの検閲を扱うことができるため、切り捨てられたデータを含む分析に適している。\n",
    "  - OLS回帰と比較して、検閲データの影響を考慮することができる。\n",
    "- **制限**:\n",
    "  - モデルの仮定が正しくない場合、結果がバイアスされる可能性がある。\n",
    "  - 分布の仮定（例えば、誤差項が正規分布に従うこと）が厳格である。\n",
    "\n",
    "### 実例\n",
    "\n",
    "以下にPythonを使って、トービットモデルを適用する例を示します。ここでは、`statsmodels`ライブラリを使用します。\n",
    "\n",
    "### コードの説明\n",
    "1. **データの作成**: 説明変数としてランダムなデータを生成し、検閲された応答変数を生成します。潜在変数 $y^*$ は観測されず、$y$ は検閲されたデータです。\n",
    "2. **TobitModelクラスの定義**: `GenericLikelihoodModel`を拡張して、トービットモデルの対数尤度関数を実装します。\n",
    "3. **トービットモデルのフィッティング**: データを用いてトービットモデルをフィッティングします。\n",
    "4. **結果の表示**: モデルの結果を表示します。\n",
    "5. **予測値の計算とプロット**: フィッティングされたモデルを使って予測値を計算し、データと共にプロットします。\n",
    "\n",
    "このカスタムトービットモデルにより、`statsmodels`を使用して検閲されたデータを分析することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 1.311465\n",
      "         Iterations: 191\n",
      "         Function evaluations: 347\n",
      "                              TobitModel Results                              \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   Log-Likelihood:                -131.15\n",
      "Model:                     TobitModel   AIC:                             268.3\n",
      "Method:            Maximum Likelihood   BIC:                             276.1\n",
      "Date:                Sat, 06 Jul 2024                                         \n",
      "Time:                        08:33:31                                         \n",
      "No. Observations:                 100                                         \n",
      "Df Residuals:                      98                                         \n",
      "Df Model:                           1                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.2151      0.169      7.208      0.000       0.885       1.545\n",
      "x1             0.4540      0.030     14.964      0.000       0.395       0.514\n",
      "par0           0.8981      0.064     14.142      0.000       0.774       1.023\n",
      "==============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taketoaramaki/study/statistics_study/.venv/lib/python3.12/site-packages/statsmodels/base/model.py:2748: UserWarning: df_model + k_constant + k_extra differs from k_params\n",
      "  warnings.warn(\"df_model + k_constant + k_extra \"\n",
      "/Users/taketoaramaki/study/statistics_study/.venv/lib/python3.12/site-packages/statsmodels/base/model.py:2752: UserWarning: df_resid differs from nobs - k_params\n",
      "  warnings.warn(\"df_resid differs from nobs - k_params\")\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 53\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(tobit_result\u001b[38;5;241m.\u001b[39msummary())\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# 予測値の計算\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mtobit_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconst\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mx1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# プロット\u001b[39;00m\n\u001b[1;32m     56\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx1\u001b[39m\u001b[38;5;124m'\u001b[39m], data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/study/statistics_study/.venv/lib/python3.12/site-packages/statsmodels/base/model.py:1174\u001b[0m, in \u001b[0;36mResults.predict\u001b[0;34m(self, exog, transform, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;124;03mCall self.model.predict with self.params as the first argument.\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1169\u001b[0m \u001b[38;5;124;03mreturned prediction.\u001b[39;00m\n\u001b[1;32m   1170\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1171\u001b[0m exog, exog_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_predict_exog(exog,\n\u001b[1;32m   1172\u001b[0m                                                 transform\u001b[38;5;241m=\u001b[39mtransform)\n\u001b[0;32m-> 1174\u001b[0m predict_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m                                     \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exog_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(predict_results,\n\u001b[1;32m   1178\u001b[0m                                           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_values\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   1179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m predict_results\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/study/statistics_study/.venv/lib/python3.12/site-packages/statsmodels/base/model.py:261\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, params, exog, *args, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, params, exog\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    256\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;124;03m    After a model has been fit predict returns the fitted values.\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \n\u001b[1;32m    259\u001b[0m \u001b[38;5;124;03m    This is a placeholder intended to be overwritten by individual models.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from statsmodels.base.model import GenericLikelihoodModel\n",
    "\n",
    "# サンプルデータの作成\n",
    "np.random.seed(42)\n",
    "n = 100\n",
    "X = np.random.rand(n) * 10\n",
    "X = sm.add_constant(X)\n",
    "beta = [1, 0.5]\n",
    "sigma = 1\n",
    "y_star = np.dot(X, beta) + np.random.normal(0, sigma, n)\n",
    "L = 0\n",
    "y = np.maximum(y_star, L)\n",
    "\n",
    "# データフレームの作成\n",
    "data = pd.DataFrame({'y': y, 'const': X[:, 0], 'x1': X[:, 1]})\n",
    "\n",
    "class TobitModel(GenericLikelihoodModel):\n",
    "    def __init__(self, endog, exog, left=0, *args, **kwargs):\n",
    "        self.left = left\n",
    "        super(TobitModel, self).__init__(endog, exog, *args, **kwargs)\n",
    "\n",
    "    def nloglikeobs(self, params):\n",
    "        exog = self.exog\n",
    "        endog = self.endog\n",
    "        left = self.left\n",
    "        beta = params[:-1]\n",
    "        sigma = params[-1]\n",
    "        xb = np.dot(exog, beta)\n",
    "        llf = np.where(endog > left,\n",
    "                       np.log(norm.pdf((endog - xb) / sigma)) - np.log(sigma),\n",
    "                       np.log(norm.cdf((left - xb) / sigma)))\n",
    "        return -llf\n",
    "\n",
    "    def fit(self, start_params=None, maxiter=10000, maxfun=5000, **kwds):\n",
    "        if start_params is None:\n",
    "            start_params = np.append(np.zeros(self.exog.shape[1]), 1)\n",
    "        return super(TobitModel, self).fit(start_params=start_params,\n",
    "                                           maxiter=maxiter, maxfun=maxfun, **kwds)\n",
    "\n",
    "# トービットモデルのフィッティング\n",
    "tobit_model = TobitModel(data['y'], data[['const', 'x1']], left=L)\n",
    "tobit_result = tobit_model.fit()\n",
    "\n",
    "# 結果の表示\n",
    "print(tobit_result.summary())\n",
    "\n",
    "# 予測値の計算\n",
    "y_pred = tobit_result.predict(data[['const', 'x1']])\n",
    "\n",
    "# プロット\n",
    "plt.scatter(data['x1'], data['y'], label=\"Data\")\n",
    "plt.plot(data['x1'], y_pred, color='red', label=\"Tobit model\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
